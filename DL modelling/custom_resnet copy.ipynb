{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "import numpy as np\n",
    "\n",
    "import skimage\n",
    "from skimage.color import rgb2hed, hed2rgb\n",
    "import pywt\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Dataset(Dataset):\n",
    "    def __init__(self, image_file, label_file, transform=None):\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load data from the H5 file\n",
    "        with h5py.File(image_file, 'r') as f:\n",
    "            self.images = f['x'][:]\n",
    "        with h5py.File(label_file, 'r') as f:\n",
    "            self.labels = f['y'][:].reshape(-1, 1).astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGB2HED(torch.nn.Module):\n",
    "    def __init__(self, mode=None):\n",
    "        super(RGB2HED, self).__init__()\n",
    "        self.mode = mode\n",
    "    def forward(self, img):\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        hed_img = rgb2hed(img) * 255.\n",
    "        hed_img = np.tile(hed_img[:, :, -2:-1], reps=(1,1,3))\n",
    "        return hed_img\n",
    "    \n",
    "        \n",
    "class WaveletTransform(nn.Module):\n",
    "    def __init__(self, wavelet='haar', threshold=20):\n",
    "        super(WaveletTransform, self).__init__()\n",
    "        self.wavelet = wavelet\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def forward(self, img):\n",
    "        grayscale_image = np.dot(img.astype(np.uint8), [0.299, 0.587, 0.114])\n",
    "        \n",
    "        # Step 2: Perform 2D wavelet decomposition\n",
    "        coeffs = pywt.wavedec2(grayscale_image, wavelet=self.wavelet, level=2)\n",
    "        cA, details = coeffs[0], coeffs[1:]\n",
    "        \n",
    "        # Step 3: Apply thresholding to detail coefficients\n",
    "        def threshold_coeffs(coeffs, threshold):\n",
    "            return [pywt.threshold(c, threshold, mode='soft') for c in coeffs] \n",
    "        \n",
    "        \n",
    "        details_thresh = [threshold_coeffs(detail, self.threshold) for detail in details]\n",
    "        coeffs_thresh = [cA] + details_thresh\n",
    "        \n",
    "        # Step 4: Reconstruct the image\n",
    "        compressed_image = pywt.waverec2(coeffs_thresh, wavelet=self.wavelet)\n",
    "        compressed_image = np.clip(compressed_image, 0, 255).astype(np.uint8)\n",
    "        compressed_image = np.tile(np.expand_dims(compressed_image, -1), (1,1,3))\n",
    "        \n",
    "        return compressed_image\n",
    "    \n",
    "\n",
    "class CLAHE(nn.Module):\n",
    "    def __init__(self, mode=None):\n",
    "        super(CLAHE, self).__init__()\n",
    "        self.mode = mode\n",
    "    def forward(self, image):\n",
    "        # Convert to LAB color space\n",
    "        lab_image = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2LAB)\n",
    "        l_channel, a, b = cv2.split(lab_image)\n",
    "\n",
    "        # Apply CLAHE to the L channel\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        l_channel = clahe.apply(l_channel)\n",
    "\n",
    "        # Merge and convert back to RGB\n",
    "        lab_image = cv2.merge((l_channel, a, b))\n",
    "        return cv2.cvtColor(lab_image, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "\n",
    "class Macenko(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Macenko, self).__init__()\n",
    "    \n",
    "    def forward(self, image):\n",
    "        \"\"\"Normalize H&E stained images using Macenko method.\"\"\"\n",
    "        # Reshape image to 2D\n",
    "        h, w, c = image.shape\n",
    "        image_flat = image.reshape((-1, c))\n",
    "\n",
    "        # PCA for stain separation\n",
    "        pca = PCA(n_components=c)\n",
    "        pca.fit(image_flat)\n",
    "        stains = pca.components_\n",
    "\n",
    "        # Normalize to intensity ranges\n",
    "        norms = np.sqrt(np.sum(stains**2, axis=0))\n",
    "        normalized_stains = stains / norms\n",
    "        normalized_image = np.dot(image_flat, normalized_stains.T)\n",
    "        \n",
    "        # Scale back and reshape\n",
    "        return normalized_image.reshape((h, w, c))\n",
    "    \n",
    "class Opening(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Opening, self).__init__()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        return skimage.morphology.opening(image)\n",
    "\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     # Opening(),\n",
    "#     # CLAHE(),\n",
    "#     # Macenko(),\n",
    "#     # WaveletTransform(),\n",
    "#     transforms.ToPILImage(),\n",
    "#     # transforms.Resize((96, 96)),\n",
    "#     transforms.ToTensor(),\n",
    "#     # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "# ])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                    transforms.ColorJitter(brightness=.5, saturation=.25,\n",
    "                                        hue=.1, contrast=.5),\n",
    "                    transforms.RandomAffine(10, (0.05, 0.05), fill=255),\n",
    "                    transforms.RandomHorizontalFlip(.5),\n",
    "                    transforms.RandomVerticalFlip(.5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.6716241, 0.48636872, 0.60884315],\n",
    "                                        [0.27210504, 0.31001145, 0.2918652])])\n",
    "val_transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize([0.6716241, 0.48636872, 0.60884315],\n",
    "                                                                      [0.27210504, 0.31001145, 0.2918652])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = H5Dataset(image_file='../../pcam/training_split.h5', \n",
    "                          label_file='../../Labels/Labels/camelyonpatch_level_2_split_train_y.h5', \n",
    "                          transform=transform)\n",
    "val_dataset = H5Dataset(image_file='../../pcam/validation_split.h5', \n",
    "                        label_file='../../Labels/Labels/camelyonpatch_level_2_split_valid_y.h5',\n",
    "                        transform=val_transform)\n",
    "\n",
    "test_dataset = H5Dataset(image_file='../../pcam/test_split.h5', \n",
    "                        label_file='../../Labels/Labels/camelyonpatch_level_2_split_test_y.h5',\n",
    "                        transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "bs = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.utils import _single, _pair, _triple\n",
    "\n",
    "\n",
    "# from torch._jit_internal import weak_module, weak_script_method\n",
    "\n",
    "\n",
    "# @weak_module\n",
    "class PolarConvNd(torch.nn.modules.conv._ConvNd):\n",
    "    def __init__(self, in_channels=1, out_channels=1, kernel_size=3, dimensions=2, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros'):\n",
    "        self.init_kernel_size = kernel_size\n",
    "        assert kernel_size % 2 == 1, 'expected kernel size to be odd, found %d' % kernel_size\n",
    "        self.init_dimensions = dimensions\n",
    "\n",
    "        self.base_vectors = torch.from_numpy(self.build_base_vectors()).float().to(device)\n",
    "        self.true_base_vectors_shape = self.base_vectors.shape\n",
    "        self.base_vectors = self.base_vectors.view(self.true_base_vectors_shape[0],\n",
    "                                                   np.prod(self.true_base_vectors_shape[1:]).astype(int))\n",
    "\n",
    "        inferred_kernel_size = self.true_base_vectors_shape[0]\n",
    "        _kernel_size = _single(inferred_kernel_size)\n",
    "        _stride = _single(stride)\n",
    "        _padding = _single(padding)\n",
    "        _dilation = _single(dilation)\n",
    "        super(PolarConvNd, self).__init__(\n",
    "            in_channels, out_channels, _kernel_size, _stride, _padding, _dilation,\n",
    "            False, _single(0), groups, bias, padding_mode)\n",
    "\n",
    "        if dimensions == 2:\n",
    "            self.reconstructed_stride = _pair(stride)\n",
    "            self.reconstructed_padding = _pair(padding)\n",
    "            self.reconstructed_dilation = _pair(dilation)\n",
    "            self.reconstructed_conv_op = F.conv2d\n",
    "        elif dimensions == 3:\n",
    "            self.reconstructed_stride = _triple(stride)\n",
    "            self.reconstructed_padding = _triple(padding)\n",
    "            self.reconstructed_dilation = _triple(dilation)\n",
    "            self.reconstructed_conv_op = F.conv3d\n",
    "        else:\n",
    "            raise ValueError('dimension %d not supported' % dimensions)\n",
    "\n",
    "    def build_base_vectors(self):\n",
    "        kernel_size = self.init_kernel_size\n",
    "        middle = kernel_size // 2\n",
    "        dimensions = self.init_dimensions\n",
    "\n",
    "        base_vectors = []\n",
    "        # Burning phase: determine the number of base vectors\n",
    "        unique_distances = []\n",
    "        if dimensions == 2:\n",
    "            for i in range(kernel_size):\n",
    "                for j in range(kernel_size):\n",
    "                    i_ = abs(i - middle)\n",
    "                    j_ = abs(j - middle)\n",
    "                    unique_distances.append(int(i_ * i_ + j_ * j_))\n",
    "        elif dimensions == 3:\n",
    "            for i in range(kernel_size):\n",
    "                for j in range(kernel_size):\n",
    "                    for k in range(kernel_size):\n",
    "                        i_ = abs(i - middle)\n",
    "                        j_ = abs(j - middle)\n",
    "                        k_ = abs(k - middle)\n",
    "                        unique_distances.append(int(i_ * i_ + j_ * j_ + k_ * k_))\n",
    "        unique_distances, distances_counts = np.unique(unique_distances, return_counts=True)\n",
    "        unique_distances = np.sort(unique_distances)\n",
    "        print(*zip(unique_distances, distances_counts), len(unique_distances))\n",
    "\n",
    "        for unique_distance, n in zip(unique_distances, distances_counts):  # number of base vectors\n",
    "            base_vector = np.zeros([kernel_size] * dimensions)\n",
    "            if dimensions == 2:\n",
    "                for i in range(kernel_size):\n",
    "                    for j in range(kernel_size):\n",
    "                        i_ = abs(i - middle)\n",
    "                        j_ = abs(j - middle)\n",
    "                        if int(i_ * i_ + j_ * j_) == unique_distance:\n",
    "                            base_vector[i, j] = 1./n\n",
    "            elif dimensions == 3:\n",
    "                for i in range(kernel_size):\n",
    "                    for j in range(kernel_size):\n",
    "                        for k in range(kernel_size):\n",
    "                            i_ = abs(i - middle)\n",
    "                            j_ = abs(j - middle)\n",
    "                            k_ = abs(k - middle)\n",
    "                            if int(i_ * i_ + j_ * j_ + k_ * k_) == unique_distance:\n",
    "                                base_vector[i, j, k] = 1./n\n",
    "            base_vectors.append(base_vector)\n",
    "        base_vectors = np.asarray(base_vectors)\n",
    "        return base_vectors\n",
    "\n",
    "    # @weak_script_method\n",
    "    def forward(self, input):\n",
    "        weight_size = self.weight.shape\n",
    "        weight = torch.mm(self.weight.view(np.prod(weight_size[:-1]), weight_size[-1]), self.base_vectors) \\\n",
    "            .view(*weight_size[:-1], *self.true_base_vectors_shape[1:])\n",
    "        return self.reconstructed_conv_op(input, weight, self.bias, self.reconstructed_stride,\n",
    "                                          self.reconstructed_padding, self.reconstructed_dilation, self.groups)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ('PolarConv%dd' % self.init_dimensions) + '(' + self.extra_repr() + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
    "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1, conv_type='classical', kernel_size=3):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    if conv_type.lower() == 'classical':\n",
    "        return nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                         padding=(kernel_size - 1) // 2, groups=groups, bias=False, dilation=dilation)\n",
    "    elif conv_type.lower() == 'polar':\n",
    "        return PolarConvNd(in_planes, out_planes, kernel_size=kernel_size, dimensions=2,\n",
    "                           stride=stride, padding=(kernel_size - 1) // 2, groups=groups, bias=False, dilation=dilation)\n",
    "    raise ValueError('unknow conv layer type %s' % conv_type)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, conv_type='classical', kernel_size=3):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, conv_type=conv_type, kernel_size=kernel_size)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, conv_type=conv_type, kernel_size=kernel_size)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, conv_type='classical', kernel_size=3):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation, conv_type=conv_type, kernel_size=kernel_size)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_type, kernel_size, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(conv_type, kernel_size, block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(conv_type, kernel_size, block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(conv_type, kernel_size, block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(conv_type, kernel_size, block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, PolarConvNd):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, conv_type, kernel_size, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer,\n",
    "                            conv_type=conv_type, kernel_size=kernel_size))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer,\n",
    "                                conv_type=conv_type, kernel_size=kernel_size))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet(arch, conv_type, kernel_size, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(conv_type, kernel_size, block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(conv_type, kernel_size, pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet18', conv_type, kernel_size, BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(conv_type, kernel_size, pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet34', conv_type, kernel_size, BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(conv_type, kernel_size, pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', conv_type, kernel_size, Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet101(conv_type, kernel_size, pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet101', conv_type, kernel_size, Bottleneck, [3, 4, 23, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnet152(conv_type, kernel_size, pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet152', conv_type, kernel_size, Bottleneck, [3, 8, 36, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "\n",
    "def resnext50_32x4d(conv_type, kernel_size, pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNeXt-50 32x4d model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 4\n",
    "    return _resnet('resnext50_32x4d', conv_type, kernel_size, Bottleneck, [3, 4, 6, 3],\n",
    "                   pretrained, progress, **kwargs)\n",
    "\n",
    "\n",
    "def resnext101_32x8d(conv_type, kernel_size, pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"Constructs a ResNeXt-101 32x8d model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 8\n",
    "    return _resnet('resnext101_32x8d', conv_type, kernel_size, Bottleneck, [3, 4, 23, 3],\n",
    "                   pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n",
      "(np.int64(0), np.int64(1)) (np.int64(1), np.int64(4)) (np.int64(2), np.int64(4)) 3\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "polar = True\n",
    "model = resnet50(conv_type='classical' if not polar else 'polar',\n",
    "                                                         kernel_size=3,\n",
    "                                                         num_classes=1)\n",
    "model = model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.5225, Train Acc: 73.47%\n",
      "Val Loss: 0.5100, Val Acc: 78.31%\n",
      "Test Loss: 0.4795, Test Acc: 79.83%\n",
      "\n",
      "\n",
      "Epoch 2/10\n",
      "Train Loss: 0.4545, Train Acc: 77.82%\n",
      "Val Loss: 0.4251, Val Acc: 76.21%\n",
      "Test Loss: 0.4416, Test Acc: 75.32%\n",
      "\n",
      "\n",
      "Epoch 3/10\n",
      "Train Loss: 0.4166, Train Acc: 79.99%\n",
      "Val Loss: 0.4203, Val Acc: 77.57%\n",
      "Test Loss: 0.4283, Test Acc: 76.58%\n",
      "\n",
      "\n",
      "Epoch 4/10\n",
      "Train Loss: 0.3806, Train Acc: 82.22%\n",
      "Val Loss: 0.4063, Val Acc: 81.64%\n",
      "Test Loss: 0.4090, Test Acc: 81.49%\n",
      "\n",
      "\n",
      "Epoch 5/10\n",
      "Train Loss: 0.3452, Train Acc: 84.38%\n",
      "Val Loss: 0.3623, Val Acc: 81.41%\n",
      "Test Loss: 0.3793, Test Acc: 81.48%\n",
      "\n",
      "\n",
      "Epoch 6/10\n",
      "Train Loss: 0.3197, Train Acc: 85.70%\n",
      "Val Loss: 0.4405, Val Acc: 83.51%\n",
      "Test Loss: 0.4427, Test Acc: 83.87%\n",
      "\n",
      "\n",
      "Epoch 7/10\n",
      "Train Loss: 0.3016, Train Acc: 86.72%\n",
      "Val Loss: 0.3733, Val Acc: 81.49%\n",
      "Test Loss: 0.4092, Test Acc: 79.17%\n",
      "\n",
      "\n",
      "Epoch 8/10\n",
      "Train Loss: 0.2908, Train Acc: 87.32%\n",
      "Val Loss: 0.3758, Val Acc: 82.79%\n",
      "Test Loss: 0.3810, Test Acc: 80.45%\n",
      "\n",
      "\n",
      "Epoch 9/10\n",
      "Train Loss: 0.2813, Train Acc: 87.76%\n",
      "Val Loss: 0.3018, Val Acc: 87.19%\n",
      "Test Loss: 0.3337, Test Acc: 85.04%\n",
      "\n",
      "\n",
      "Epoch 10/10\n",
      "Train Loss: 0.2740, Train Acc: 88.18%\n",
      "Val Loss: 0.3217, Val Acc: 86.12%\n",
      "Test Loss: 0.3343, Test Acc: 85.15%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and validation loops\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Metrics\n",
    "            train_loss += loss.item()\n",
    "            train_correct += ((outputs > .5).float() == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            # train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Metrics\n",
    "                val_loss += loss.item()\n",
    "                val_correct += ((outputs > .5).float() == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                # val_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "        # Test phase\n",
    "        model.eval()\n",
    "        test_loss, test_correct, test_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Metrics\n",
    "                test_loss += loss.item()\n",
    "                test_correct += ((outputs > .5).float() == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "                # test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {100 * train_correct/train_total:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {100 * val_correct/val_total:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss/len(test_loader):.4f}, Test Acc: {100 * test_correct/test_total:.2f}%\\n\\n\")\n",
    "\n",
    "# Train and validate the model\n",
    "train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1124503448.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    Test Loss: 0.6932, Test Acc: 50.02%\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# le = 1e-3, wd = 1e-6\n",
    "\n",
    "# Epoch 1/10\n",
    "# Train Loss: 0.6988, Train Acc: 50.10%\n",
    "# Val Loss: 0.6933, Val Acc: 50.05%\n",
    "# Test Loss: 0.6933, Test Acc: 50.02%\n",
    "\n",
    "\n",
    "# Epoch 2/10\n",
    "# Train Loss: 0.6932, Train Acc: 50.00%\n",
    "# Val Loss: 0.6932, Val Acc: 50.05%\n",
    "# Test Loss: 0.6932, Test Acc: 50.02%\n",
    "\n",
    "\n",
    "# Epoch 3/10\n",
    "# Train Loss: 0.6932, Train Acc: 50.00%\n",
    "# Val Loss: 0.6933, Val Acc: 50.05%\n",
    "# Test Loss: 0.6933, Test Acc: 50.02%\n",
    "\n",
    "\n",
    "# Epoch 4/10\n",
    "# Train Loss: 0.6932, Train Acc: 50.00%\n",
    "# Val Loss: 0.6933, Val Acc: 50.05%\n",
    "# Test Loss: 0.6934, Test Acc: 50.02%\n",
    "\n",
    "\n",
    "# Epoch 5/10\n",
    "# Train Loss: 0.6932, Train Acc: 50.00%\n",
    "# Val Loss: 0.6932, Val Acc: 50.05%\n",
    "# Test Loss: 0.6931, Test Acc: 50.02%\n",
    "\n",
    "\n",
    "# Epoch 6/10\n",
    "# Train Loss: 0.6932, Train Acc: 50.00%\n",
    "# Val Loss: 0.6932, Val Acc: 50.05%\n",
    "Test Loss: 0.6932, Test Acc: 50.02%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
